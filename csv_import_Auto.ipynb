{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inappropriate-bahamas",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "\n",
    "- import the CSV file into pandas dataframe\n",
    "- clean the table name and remove all symbols, spaces, capital letters\n",
    "- clean the column headers and remove all symbols, spaces, capital letters\n",
    "- write the create table SQL statement\n",
    "- import the data into the DB\n",
    "\n",
    "#### Capabilites\n",
    "- handle multiple files\n",
    "- completely automatic (no code editing neccesary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sacred-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "southwest-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find CSV files in current directory\n",
    "#pick only CSV files\n",
    "\n",
    "\n",
    "os.chdir(r'C:/Users/user/Desktop/SampleData/datasets/')\n",
    "\n",
    "csv_files = []\n",
    "for file in os.listdir(os.getcwd()):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tropical-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new dir\n",
    "dataset_dir = 'datasets'\n",
    "\n",
    "#create bash command for new dir\n",
    "#  mkdir dataset_dir\n",
    "\n",
    "try:\n",
    "    mkdir = 'mkdir {0}'.format(dataset_dir)\n",
    "    os.system(mkdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "short-rebel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mv 'Customer Contracts$.csv' datasets\n",
      " mv 'Customer Demo.csv' datasets\n",
      " mv 'Customer Engagements.csv' datasets\n",
      " mv 'DATA$@SAMPLE.csv' datasets\n",
      " mv 'data_sample.csv' datasets\n"
     ]
    }
   ],
   "source": [
    "#move CSV files into the new dir\n",
    "\n",
    "for csv in csv_files:\n",
    "    \n",
    "    mv_file =\"mv '{0}' {1}\".format(csv, dataset_dir)\n",
    "    os.system(mv_file)\n",
    "    print(mv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "supported-housing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Contracts$.csv\n",
      "Customer Demo.csv\n",
      "Customer Engagements.csv\n",
      "DATA$@SAMPLE.csv\n"
     ]
    }
   ],
   "source": [
    "#create dataframe for each CSV file\n",
    "data_path = os.getcwd()+'/'+dataset_dir+'/'\n",
    "\n",
    "df = {}\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df[file] = pd.read_csv(data_path+file)\n",
    "    except UnicodeDecodeError:\n",
    "        df[file] = pd.read_csv(data_path+file, encoding=\"ISO-8859-1\")\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "pleased-joseph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened db\n",
      "customer_contracts was created\n",
      "file is open in memory\n",
      "file copied to db\n",
      "table customer_contracts import to db is completed\n",
      "opened db\n",
      "customer_demo was created\n",
      "file is open in memory\n",
      "file copied to db\n",
      "table customer_demo import to db is completed\n",
      "opened db\n",
      "customer_engagements was created\n",
      "file is open in memory\n",
      "file copied to db\n",
      "table customer_engagements import to db is completed\n",
      "opened db\n",
      "data_sample was created\n",
      "file is open in memory\n",
      "file copied to db\n",
      "table data_sample import to db is completed\n",
      "all tables have been imported into the DB.\n"
     ]
    }
   ],
   "source": [
    "#clean table & column names\n",
    "# have only lower case letters\n",
    "# remove all symbols\n",
    "# replace space, -, /, @ with _\n",
    "for k in csv_files:\n",
    "    \n",
    "    dataframe = df[k]\n",
    "    \n",
    "    clean_table_name = k.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "                       .replace(\"-\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\") \\\n",
    "                       .replace(\"$\",\"\").replace(\"@\",\"_\").replace(r\"(\",\"\") \\\n",
    "                       .replace(r\")\",\"\").replace(\"%\",\"\")\n",
    "    \n",
    "    \n",
    "    #remove .csv ext\n",
    "    tbl_name = '{0}'.format(clean_table_name.split('.')[0])\n",
    "    \n",
    "    \n",
    "    dataframe.columns = [x.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "                       .replace(\"-\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\") \\\n",
    "                       .replace(\"$\",\"\").replace(\"@\",\"_\").replace(r\"(\",\"\") \\\n",
    "                       .replace(r\")\",\"\").replace(\"%\",\"\") for x in dataframe.columns]\n",
    "    \n",
    "    \n",
    "    #replacement dictionary that maps pandas dtypes to sql dtypes\n",
    "    dt_replacements = {\n",
    "    'object' : 'varchar' ,\n",
    "    'int64' : 'int' ,\n",
    "    'float64' : 'float' ,\n",
    "    'datetime64' : 'timestamp' ,\n",
    "    'timedelta64[ns]' : 'varchar'\n",
    "    }\n",
    "    \n",
    "    #table schema\n",
    "    col_str = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip(dataframe.columns, dataframe.dtypes.replace(dt_replacements)))\n",
    "    \n",
    "    #open connection to DB\n",
    "    host = 'ronamazoninstance.c9n0aimuu7iu.eu-central-1.rds.amazonaws.com'\n",
    "    dbname = 'rondb'\n",
    "    user = 'ronadmin'\n",
    "    password = 'Korki123'\n",
    "\n",
    "    conn_string = \"host=%s dbname=%s user=%s password=%s\" % (host, dbname, user, password)\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cursor = conn.cursor()               \n",
    "    print('opened db')\n",
    "    \n",
    "    #drop potential duplicate tables\n",
    "    cursor.execute(\"drop table if exists %s;\" % (tbl_name))\n",
    "    \n",
    "    #create the table\n",
    "    cursor.execute(\"create table %s (%s);\" % (tbl_name, col_str))\n",
    "    print('{0} was created'.format(tbl_name))\n",
    "    \n",
    "    #insert values into table\n",
    "\n",
    "    #save df to csv\n",
    "    dataframe.to_csv(k, header=dataframe.columns, index=False, encoding='utf-8')\n",
    "\n",
    "    #open the csv file, save as an object\n",
    "    my_file = open(k)\n",
    "    print('file is open in memory')\n",
    "    \n",
    "    #upload the file and inesrt into the DB\n",
    "\n",
    "    SQL_STATEMENT = \"\"\"\n",
    "    COPY %s FROM STDIN WITH\n",
    "     CSV\n",
    "     HEADER\n",
    "     DELIMITER AS ','\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.copy_expert(sql=SQL_STATEMENT % tbl_name, file=my_file)\n",
    "    print('file copied to db')\n",
    "    \n",
    "    #give permissions on table to anyone and close the connection\n",
    "    cursor.execute(\"grant select on table %s to public\" % tbl_name)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print('table {0} import to db is completed'.format(tbl_name))\n",
    "    \n",
    "#for end message\n",
    "print('all tables have been imported into the DB.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
